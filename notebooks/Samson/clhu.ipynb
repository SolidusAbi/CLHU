{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys\n",
    "project_root_dir = os.path.join(os.getcwd(),'../..')\n",
    "if project_root_dir not in sys.path:\n",
    "    sys.path.append(project_root_dir)\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "from torch import nn\n",
    "import torch\n",
    "import config\n",
    "\n",
    "from utils import show_abundance, plot_endmembers\n",
    "from HySpecLab.metrics import rmse, sad\n",
    "from scipy import io as sio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataset import Samson\n",
    "\n",
    "dataset = Samson(config.Samson_PATH)\n",
    "result_path = os.path.join(config.RESULTS_PATH, 'samson')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ground Truth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import plot_endmembers, show_abundance\n",
    "fig = plot_endmembers(dataset.endmembers(), ticks_range=(0, 1))\n",
    "plt.show(fig)\n",
    "# fig.savefig(os.path.join(result_path, 'imgs/M_ref.pdf'), bbox_inches='tight')\n",
    "\n",
    "fig = show_abundance(dataset.abundance())\n",
    "plt.show(fig)\n",
    "# fig.savefig(os.path.join(result_path, 'imgs/A_ref.png'), dpi=300, bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from HySpecLab.metrics import sad\n",
    "\n",
    "def sort_endmember(endmembers, gt):\n",
    "    sad_result = sad(endmembers, gt)\n",
    "    e_idx = torch.argmin(sad_result, dim=0) # Index for reordering the ground truth\n",
    "    return e_idx, sad_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from HySpecLab.eea import VCA\n",
    "\n",
    "n_endmembers = dataset.n_endmembers\n",
    "   \n",
    "vca = VCA(n_endmembers, snr_input=1, random_state=42)\n",
    "vca.fit(dataset.X.numpy())\n",
    "endmembers = torch.from_numpy(vca.endmembers()).float()\n",
    "e_idx, sad_result = sort_endmember(endmembers, dataset.endmembers())\n",
    "\n",
    "vca_endmember_init = endmembers[e_idx]\n",
    "vca_logit_endmember_init = torch.log((vca_endmember_init + 1e-12) / ((1-vca_endmember_init) + 1e-12))\n",
    "\n",
    "fig = plot_endmembers(vca_endmember_init, ticks_range=(0, 1))\n",
    "plt.show(fig)\n",
    "\n",
    "# fig.savefig(os.path.join(result_path, 'imgs/M_vca.pdf'), bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import plot_endmembers\n",
    "from pysptools import eea\n",
    "n_endmembers = dataset.n_endmembers \n",
    "\n",
    "ee = eea.NFINDR()\n",
    "endmember = torch.from_numpy(ee.extract(dataset.image(), n_endmembers)).float()\n",
    "\n",
    "e_idx, _ = sort_endmember(endmember, dataset.endmembers())\n",
    "nfindr_endmember_init = endmember[e_idx]\n",
    "nfindr_logit_endmember_init = torch.log((nfindr_endmember_init + 1e-12) / ((1-vca_endmember_init) + 1e-12))\n",
    "\n",
    "fig = plot_endmembers(nfindr_endmember_init, ticks_range=(0, 1))\n",
    "plt.show(fig)\n",
    "# fig.savefig(os.path.join(result_path, 'imgs/M_nfindr.pdf'), bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plot_endmembers(dataset.endmembers(), ticks_range=(0, 1), endmember_estimation=[nfindr_endmember_init, vca_endmember_init], ee_labels=['Ground Truth', 'N-FINDR', 'VCA'])\n",
    "plt.show(fig)\n",
    "# fig.savefig(os.path.join(result_path, 'imgs/M_estimation.pdf'), bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# endmembers_dict = {'NFINDR': nfindr_endmember_init.numpy(), 'VCA': vca_endmember_init.numpy()}\n",
    "\n",
    "# sio.savemat(os.path.join(result_path, 'matlab/endmember_estimation.mat'), endmembers_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "endmember_init_method = 'nfindr'\n",
    "endmember_init = nfindr_endmember_init\n",
    "logit_endmember_init = nfindr_logit_endmember_init\n",
    "\n",
    "# endmember_init_method = 'vca'\n",
    "# endmember_init = vca_endmember_init\n",
    "# logit_endmember_init = vca_logit_endmember_init"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import train \n",
    "from HySpecLab.unmixing import ContrastiveUnmixing\n",
    "\n",
    "n_bands = dataset.n_bands\n",
    "model = ContrastiveUnmixing(n_bands, n_endmembers, endmember_init=logit_endmember_init, sigma_sparsity=.5)\n",
    "_ = model(dataset.X)\n",
    "print(model.sparse_gate.regularize().detach())\n",
    "# train(model, n_endmembers, dataset, n_batchs=50, n_epochs=50, lr=1e-3, simplex_weight=5e-3)\n",
    "train(model, n_endmembers, dataset, n_batchs=100, n_epochs=100, lr=1e-3, similarity_weight=1, sparse_weight=.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = ContrastiveUnmixing(n_bands, n_endmembers, endmember_init=logit_endmember_init, sigma_sparsity=.1)\n",
    "model.eval()\n",
    "z = model.encoder(dataset.X.cuda())\n",
    "model.sparse_gate(z).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "_ = model(dataset.X.cuda())\n",
    "print(model.sparse_gate.variational_parameter().flatten())\n",
    "print(model.sparse_gate.variational_parameter().flatten().mean())\n",
    "print(model.sparse_gate.variational_parameter().flatten().min())\n",
    "print(model.sparse_gate.regularize())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), os.path.join(result_path, f'clhu/weights/clhu_{endmember_init_method}.pth'))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from HySpecLab.unmixing import ContrastiveUnmixing\n",
    "\n",
    "# load model\n",
    "# model = ContrastiveUnmixing(dataset.n_bands, dataset.n_endmembers)\n",
    "\n",
    "# model.load_state_dict(torch.load(os.path.join(result_path, 'clhu/weights/clhu.pth')))\n",
    "model = model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from HySpecLab.metrics.regularization import SimplexVolumeLoss, SimilarityLoss\n",
    "from HySpecLab.metrics import UnmixingLoss, NormalizedEntropy\n",
    "\n",
    "criterion = UnmixingLoss()\n",
    "entropy_reg  = NormalizedEntropy(S=n_endmembers)\n",
    "volume_reg = SimplexVolumeLoss(dataset[:], n_endmembers)\n",
    "similarity_reg = SimilarityLoss(n_endmembers, temperature=.1, reduction='mean')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import sigmoid \n",
    "_X = dataset.X\n",
    "\n",
    "model.eval()\n",
    "model = model.cpu()\n",
    "reconstruc = model(_X)\n",
    "with torch.no_grad():\n",
    "    print(criterion(reconstruc, _X).cpu(), entropy_reg(model.A).cpu(), volume_reg(sigmoid(model.ebk)).cpu(),\n",
    "         similarity_reg(model.ebk).cpu())\n",
    "        #  similarity_reg(sigmoid(model.ebk)).cpu())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "volume_reg(endmember_init), similarity_reg(logit_endmember_init)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(reconstruc[:, 25].detach().reshape(95,95), cmap='viridis')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "volume_reg(endmember_init), similarity_reg(logit_endmember_init)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ebk = torch.sigmoid(model.ebk).detach().cpu()\n",
    "if endmember_init_method == 'vca':\n",
    "    label = 'VCA'\n",
    "else:\n",
    "    label = 'N-FINDR'\n",
    "fig = plot_endmembers(ebk, ticks_range=(0, 1), endmember_estimation=[endmember_init], ee_labels=['CLHU',label])\n",
    "plt.show(fig)\n",
    "fig.savefig(os.path.join(result_path, f'clhu/imgs/M_clhu_{endmember_init_method}.pdf'), bbox_inches='tight')\n",
    "\n",
    "# fig = plot_endmembers(ebk, ticks_range=(0, 1))\n",
    "# plt.show(fig)\n",
    "# fig.savefig(os.path.join(result_path, 'clhu/imgs/M_clhu_2.pdf'), bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.nn.functional import softmax\n",
    "test = softmax(model.A.detach(), dim=1).cpu().numpy().reshape(dataset.n_row, dataset.n_col, -1)\n",
    "\n",
    "fig = show_abundance(test, transpose=False, cmap='viridis')\n",
    "plt.show(fig)\n",
    "\n",
    "fig.savefig(os.path.join(result_path, f'clhu/imgs/A_clhu_estimation_{endmember_init_method}.pdf'), dpi=300, bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test = model._sparse.detach().cpu().numpy().reshape(dataset.n_row, dataset.n_col)\n",
    "test = model.sparse_gate.variational_parameter().detach().cpu().numpy().reshape(dataset.n_row, dataset.n_col)\n",
    "test = np.log(test)\n",
    "plt.imshow(test, cmap='jet')\n",
    "plt.colorbar()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "X_true = dataset.A @ dataset.endmembers()\n",
    "# X_true = dataset.X\n",
    "X_hat = model(dataset.X).detach().cpu()\n",
    "A_hat = torch.softmax(model.A.detach().cpu(), dim=1)\n",
    "M_hat = sigmoid(model.ebk.detach().cpu())\n",
    "\n",
    "_M_hat = model(M_hat).detach().cpu()\n",
    "\n",
    "import pandas as pd\n",
    "df = pd.DataFrame(columns=['Method', 'RMSE_X', 'RMSE_A', 'SAD_M'])\n",
    "df['Method'] = ['CLHU']\n",
    "df['RMSE_X'] = [rmse(X_true, X_hat, dim=None).numpy()]\n",
    "df['RMSE_A'] = [rmse(dataset.A, A_hat, dim=None).numpy()]\n",
    "\n",
    "sad_result = sad(M_hat, dataset.endmembers()).numpy()\n",
    "# sad_result = sad(_M_hat, dataset.endmembers()).numpy()\n",
    "\n",
    "df['SAD_M'] = np.diagonal(sad_result).mean()\n",
    "\n",
    "# df.to_csv(os.path.join(result_path, 'clhu/metrics.csv'), index=False)\n",
    "print(np.diagonal(sad(_M_hat, dataset.endmembers()).numpy()).mean())\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_M_hat = torch.sigmoid(model.ebk.cpu()).detach()\n",
    "plt.plot(_M_hat.T)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.subplot(1,2,1)\n",
    "plt.plot(M_hat.detach().cpu().numpy().T)\n",
    "plt.subplot(1,2,2)\n",
    "plt.plot(_M_hat.detach().cpu().numpy().T)\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from HySpecLab.metrics import rmse\n",
    "from torch import sigmoid\n",
    "def test(model, dataset):\n",
    "    X = dataset.X\n",
    "    model.eval()\n",
    "    model = model.cpu()\n",
    "    \n",
    "    X_true = dataset.A @ dataset.endmembers()\n",
    "    with torch.no_grad():\n",
    "        X_hat = model(dataset.X)\n",
    "        A_hat = torch.softmax(model.A, dim=1)\n",
    "        M_hat = sigmoid(model.ebk) \n",
    "    \n",
    "    rmse_x = rmse(X_true, X_hat, dim=None).numpy()      \n",
    "    rmse_a = rmse(dataset.A, A_hat, dim=None).numpy()\n",
    "    sad_m = np.diagonal(sad(M_hat, dataset.endmembers()).numpy()).mean()\n",
    "    return rmse_x.item(), rmse_a.item(), sad_m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from HySpecLab.unmixing import ContrastiveUnmixing\n",
    "\n",
    "n_bands = dataset.n_bands\n",
    "\n",
    "batch_rmse_x = []\n",
    "batch_rmse_a = []\n",
    "batch_sad_m = []\n",
    "for i in range(10):\n",
    "    model = ContrastiveUnmixing(n_bands, n_endmembers, endmember_init=logit_endmember_init, sigma_sparsity=.5)\n",
    "    train(model, n_endmembers, dataset, n_batchs=100, n_epochs=100, lr=1e-3, similarity_weight=1, sparse_weight=.9)\n",
    "\n",
    "    rmse_x, rmse_a, sad_m = test(model, dataset)\n",
    "    batch_rmse_x.append(rmse_x)\n",
    "    batch_rmse_a.append(rmse_a)\n",
    "    batch_sad_m.append(sad_m)\n",
    "\n",
    "    print(rmse_x, rmse_a, sad_m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate dataframe\n",
    "import pandas as pd\n",
    "df = pd.DataFrame(columns=['RMSE_X', 'RMSE_A', 'SAD_M'])\n",
    "df['RMSE_X'] = batch_rmse_x\n",
    "df['RMSE_A'] = batch_rmse_a\n",
    "df['SAD_M'] = batch_sad_m\n",
    "\n",
    "# extract mean and std\n",
    "df['RMSE_X'].mean(), df['RMSE_X'].std(), df['RMSE_A'].mean(), df['RMSE_A'].std(), df['SAD_M'].mean(), df['SAD_M'].std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(os.path.join(result_path, 'clhu/metrics_{}_batch.csv'.format(endmember_init_method)), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "CLHU",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
