{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys\n",
    "project_root_dir = os.path.join(os.getcwd(),'../..')\n",
    "if project_root_dir not in sys.path:\n",
    "    sys.path.append(project_root_dir)\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "from torch import nn\n",
    "import torch\n",
    "import config\n",
    "\n",
    "from utils import show_abundance, plot_endmembers\n",
    "# from dataset import JasperRidgeDataset\n",
    "from HySpecLab.metrics import rmse, sad\n",
    "from scipy import io as sio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataset import JasperRidge\n",
    "\n",
    "dataset = JasperRidge(config.JasperRidge_PATH)\n",
    "dataset_name = 'JasperRidge'\n",
    "wv = np.array(dataset.wv, dtype=np.uint)\n",
    "\n",
    "result_path = os.path.join(config.RESULTS_PATH, 'jasperRidge')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ground Truth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import plot_endmembers, show_abundance\n",
    "fig = plot_endmembers(dataset.endmembers(), wv, ticks_range=(0, 1), n_ticks=5)\n",
    "plt.show(fig)\n",
    "# fig.savefig(os.path.join(result_path, 'imgs/M_ref.pdf'), bbox_inches='tight')\n",
    "\n",
    "fig = show_abundance(dataset.abundance())\n",
    "plt.show(fig)\n",
    "# fig.savefig(os.path.join(result_path, 'imgs/A_ref.png'), dpi=300, bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from HySpecLab.metrics import sad\n",
    "\n",
    "def sort_endmember(endmembers, gt):\n",
    "    sad_result = sad(endmembers, gt)\n",
    "    e_idx = torch.argmin(sad_result, dim=0) # Index for reordering the ground truth\n",
    "    return e_idx, sad_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from HySpecLab.eea import VCA\n",
    "\n",
    "n_endmembers = dataset.n_endmembers\n",
    "   \n",
    "vca = VCA(n_endmembers, snr_input=-1, random_state=25)\n",
    "vca.fit(dataset.X.numpy())\n",
    "endmembers = torch.from_numpy(vca.endmembers()).float()\n",
    "e_idx, sad_result = sort_endmember(endmembers, dataset.endmembers())\n",
    "\n",
    "vca_endmember_init = endmembers[e_idx]\n",
    "vca_logit_endmember_init = torch.log((vca_endmember_init + 1e-12) / ((1-vca_endmember_init) + 1e-12))\n",
    "\n",
    "fig = plot_endmembers(vca_endmember_init, wv, ticks_range=(0, 1))\n",
    "plt.show(fig)\n",
    "\n",
    "# fig.savefig(os.path.join(result_path, 'imgs/M_vca.pdf'), bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import plot_endmembers\n",
    "from pysptools import eea\n",
    "n_endmembers = dataset.n_endmembers\n",
    "\n",
    "ee = eea.NFINDR()\n",
    "endmember = torch.from_numpy(ee.extract(dataset.image(), n_endmembers)).float()\n",
    "\n",
    "e_idx, _ = sort_endmember(endmember, dataset.endmembers())\n",
    "nfindr_endmember_init = endmember[e_idx]\n",
    "nfindr_logit_endmember_init = torch.log((nfindr_endmember_init + 1e-12) / ((1-vca_endmember_init) + 1e-12))\n",
    "\n",
    "fig = plot_endmembers(nfindr_endmember_init, wv, ticks_range=(0, 1))\n",
    "plt.show(fig)\n",
    "# fig.savefig(os.path.join(result_path, 'imgs/M_nfindr.pdf'), bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plot_endmembers(dataset.endmembers() / dataset.endmembers().max(), wv, ticks_range=(0, 1), endmember_estimation=[nfindr_endmember_init, vca_endmember_init], ee_labels=['Ground Truth', 'N-FINDR', 'VCA'])\n",
    "plt.show(fig)\n",
    "# fig.savefig(os.path.join(result_path, 'imgs/M_estimation.pdf'), bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# endmember_init_method = 'nfindr'\n",
    "# endmember_init = nfindr_endmember_init\n",
    "# logit_endmember_init = nfindr_logit_endmember_init\n",
    "\n",
    "endmember_init_method = 'vca'\n",
    "endmember_init = vca_endmember_init\n",
    "logit_endmember_init = vca_logit_endmember_init"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {\n",
    "    'sigma_sparsity': [.05, .1, .25, .5],\n",
    "    'sparse_weight': [0, .05, .1, .25, .5, 1],\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import sigmoid\n",
    "def test(model, dataset):\n",
    "    X = dataset.X\n",
    "    model.eval()\n",
    "    model = model.cpu()\n",
    "    \n",
    "    X_true = dataset.A @ dataset.endmembers()\n",
    "    with torch.no_grad():\n",
    "        X_hat = model(dataset.X)\n",
    "        A_hat = torch.softmax(model.A, dim=1)\n",
    "        M_hat = sigmoid(model.ebk) \n",
    "    \n",
    "    rmse_x = rmse(X_true, X_hat, dim=None).numpy()      \n",
    "    rmse_a = rmse(dataset.A, A_hat, dim=None).numpy()\n",
    "    sad_m = np.diagonal(sad(M_hat, dataset.endmembers()).numpy()).mean()\n",
    "    return rmse_x.item(), rmse_a.item(), sad_m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import ParameterGrid\n",
    "from utils import train \n",
    "from HySpecLab.unmixing import ContrastiveUnmixing\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "\n",
    "n_bands = dataset.n_bands\n",
    "results = pd.DataFrame(columns=['sigma_sparsity', 'sparse_weight', 'mean_rmse_x', 'mean_rmse_a', 'mean_sad_m'])\n",
    "for params in ParameterGrid(param_grid):\n",
    "    sigma = params['sigma_sparsity']\n",
    "    sparse_weight = params['sparse_weight']\n",
    "    batch_rmse_x, batch_rmse_a, batch_sad_m = [], [], []\n",
    "\n",
    "    for i in tqdm(range(5)):\n",
    "        model = ContrastiveUnmixing(n_bands, n_endmembers, endmember_init=logit_endmember_init, sigma_sparsity=sigma)\n",
    "        train(model, n_endmembers, dataset, n_batchs=50, n_epochs=100, lr=1e-3, similarity_weight=1, sparse_weight=sparse_weight)\n",
    "        rmse_x, rmse_a, sad_m = test(model, dataset)\n",
    "        batch_rmse_x.append(rmse_x)\n",
    "        batch_rmse_a.append(rmse_a)\n",
    "        batch_sad_m.append(sad_m)\n",
    "\n",
    "    mean_rmse_x = sum(batch_rmse_x) / len(batch_rmse_x)\n",
    "    mean_rmse_a = sum(batch_rmse_a) / len(batch_rmse_a)\n",
    "    mean_sad_m = sum(batch_sad_m) / len(batch_sad_m)\n",
    "    \n",
    "    results = results.append({'sigma_sparsity': sigma, 'sparse_weight': sparse_weight, 'mean_rmse_x': mean_rmse_x, 'mean_rmse_a': mean_rmse_a, 'mean_sad_m': mean_sad_m}, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_save_path = os.path.join(result_path, 'hyperparameters.csv')\n",
    "results.to_csv(csv_save_path, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Apex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataset import Apex\n",
    "dataset = Apex(config.Apex_PATH)\n",
    "\n",
    "result_path = os.path.join(config.RESULTS_PATH, 'apex')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "fig = plot_endmembers(dataset.endmembers(), np.array(dataset.wv), ticks_range=(0, .5), n_ticks=5)\n",
    "plt.show(fig)\n",
    "# fig.savefig(os.path.join(result_path, 'imgs/M_ref.pdf'), bbox_inches='tight')\n",
    "\n",
    "fig = show_abundance(dataset.abundance())\n",
    "plt.show(fig)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from HySpecLab.eea import VCA\n",
    "\n",
    "n_endmembers = dataset.n_endmembers\n",
    "   \n",
    "vca = VCA(n_endmembers, snr_input=20, random_state=42)\n",
    "vca.fit(dataset.X.numpy())\n",
    "endmembers = torch.from_numpy(vca.endmembers()).float()\n",
    "e_idx, sad_result = sort_endmember(endmembers, dataset.endmembers())\n",
    "\n",
    "vca_endmember_init = endmembers[e_idx]\n",
    "vca_logit_endmember_init = torch.log((vca_endmember_init + 1e-12) / ((1-vca_endmember_init) + 1e-12))\n",
    "\n",
    "fig = plot_endmembers(vca_endmember_init, dataset.wv, ticks_range=(0, 1))\n",
    "plt.show(fig)\n",
    "\n",
    "endmember_init_method = 'vca'\n",
    "endmember_init = vca_endmember_init\n",
    "logit_endmember_init = vca_logit_endmember_init"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import ParameterGrid\n",
    "from utils import train \n",
    "from HySpecLab.unmixing import ContrastiveUnmixing\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "\n",
    "n_bands = dataset.n_bands\n",
    "results = pd.DataFrame(columns=['sigma_sparsity', 'sparse_weight', 'mean_rmse_x', 'mean_rmse_a', 'mean_sad_m'])\n",
    "for params in ParameterGrid(param_grid):\n",
    "    sigma = params['sigma_sparsity']\n",
    "    sparse_weight = params['sparse_weight']\n",
    "    print('Sigma:', sigma, 'Sparse Weight:', sparse_weight)\n",
    "    batch_rmse_x, batch_rmse_a, batch_sad_m = [], [], []\n",
    "\n",
    "    for i in tqdm(range(3)):\n",
    "        model = ContrastiveUnmixing(n_bands, n_endmembers, endmember_init=logit_endmember_init, sigma_sparsity=sigma)\n",
    "        train(model, n_endmembers, dataset, n_batchs=50, n_epochs=100, lr=1e-3, similarity_weight=1, sparse_weight=sparse_weight)\n",
    "        rmse_x, rmse_a, sad_m = test(model, dataset)\n",
    "        batch_rmse_x.append(rmse_x)\n",
    "        batch_rmse_a.append(rmse_a)\n",
    "        batch_sad_m.append(sad_m)\n",
    "\n",
    "    mean_rmse_x = sum(batch_rmse_x) / len(batch_rmse_x)\n",
    "    mean_rmse_a = sum(batch_rmse_a) / len(batch_rmse_a)\n",
    "    mean_sad_m = sum(batch_sad_m) / len(batch_sad_m)\n",
    "    \n",
    "    results = results.append({'sigma_sparsity': sigma, 'sparse_weight': sparse_weight, 'mean_rmse_x': mean_rmse_x, 'mean_rmse_a': mean_rmse_a, 'mean_sad_m': mean_sad_m}, ignore_index=True)\n",
    "    print('Mean RMSE X:', mean_rmse_x, 'Mean RMSE A:', mean_rmse_a, 'Mean SAD M:', mean_sad_m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_save_path = os.path.join(result_path, 'hyperparameters.csv')\n",
    "results.to_csv(csv_save_path, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Samson"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataset import Samson\n",
    "\n",
    "dataset = Samson(config.Samson_PATH)\n",
    "result_path = os.path.join(config.RESULTS_PATH, 'samson')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plot_endmembers(dataset.endmembers(), np.array(dataset.wv), ticks_range=(0, .5), n_ticks=5)\n",
    "plt.show(fig)\n",
    "\n",
    "fig = show_abundance(dataset.abundance())\n",
    "plt.show(fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from HySpecLab.eea import VCA\n",
    "\n",
    "n_endmembers = dataset.n_endmembers\n",
    "   \n",
    "vca = VCA(n_endmembers, snr_input=20, random_state=42)\n",
    "vca.fit(dataset.X.numpy())\n",
    "endmembers = torch.from_numpy(vca.endmembers()).float()\n",
    "e_idx, sad_result = sort_endmember(endmembers, dataset.endmembers())\n",
    "\n",
    "vca_endmember_init = endmembers[e_idx]\n",
    "vca_logit_endmember_init = torch.log((vca_endmember_init + 1e-12) / ((1-vca_endmember_init) + 1e-12))\n",
    "\n",
    "fig = plot_endmembers(vca_endmember_init, dataset.wv, ticks_range=(0, 1))\n",
    "plt.show(fig)\n",
    "\n",
    "endmember_init_method = 'vca'\n",
    "endmember_init = vca_endmember_init\n",
    "logit_endmember_init = vca_logit_endmember_init"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import ParameterGrid\n",
    "from utils import train \n",
    "from HySpecLab.unmixing import ContrastiveUnmixing\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "\n",
    "n_bands = dataset.n_bands\n",
    "results = pd.DataFrame(columns=['sigma_sparsity', 'sparse_weight', 'mean_rmse_x', 'mean_rmse_a', 'mean_sad_m'])\n",
    "for params in ParameterGrid(param_grid):\n",
    "    sigma = params['sigma_sparsity']\n",
    "    sparse_weight = params['sparse_weight']\n",
    "    print('Sigma:', sigma, 'Sparse Weight:', sparse_weight)\n",
    "    batch_rmse_x, batch_rmse_a, batch_sad_m = [], [], []\n",
    "\n",
    "    for i in tqdm(range(3)):\n",
    "        model = ContrastiveUnmixing(n_bands, n_endmembers, endmember_init=logit_endmember_init, sigma_sparsity=sigma)\n",
    "        train(model, n_endmembers, dataset, n_batchs=50, n_epochs=100, lr=1e-3, similarity_weight=1, sparse_weight=sparse_weight)\n",
    "        rmse_x, rmse_a, sad_m = test(model, dataset)\n",
    "        batch_rmse_x.append(rmse_x)\n",
    "        batch_rmse_a.append(rmse_a)\n",
    "        batch_sad_m.append(sad_m)\n",
    "\n",
    "    mean_rmse_x = sum(batch_rmse_x) / len(batch_rmse_x)\n",
    "    mean_rmse_a = sum(batch_rmse_a) / len(batch_rmse_a)\n",
    "    mean_sad_m = sum(batch_sad_m) / len(batch_sad_m)\n",
    "    \n",
    "    results = results.append({'sigma_sparsity': sigma, 'sparse_weight': sparse_weight, 'mean_rmse_x': mean_rmse_x, 'mean_rmse_a': mean_rmse_a, 'mean_sad_m': mean_sad_m}, ignore_index=True)\n",
    "    print('Mean RMSE X:', mean_rmse_x, 'Mean RMSE A:', mean_rmse_a, 'Mean SAD M:', mean_sad_m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_save_path = os.path.join(result_path, 'hyperparameters.csv')\n",
    "results.to_csv(csv_save_path, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "M_hat = sigmoid(model.ebk.detach().cpu()).numpy()\n",
    "\n",
    "fig = plot_endmembers(M_hat, dataset.wv, ticks_range=(0, 1))\n",
    "plt.show(fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test = model._sparse.detach().cpu().numpy().reshape(dataset.n_row, dataset.n_col)\n",
    "test = model.sparse_gate.variational_parameter().detach().cpu().numpy().reshape(dataset.n_row, dataset.n_col)\n",
    "test = np.log(test)\n",
    "fig = plt.figure(figsize=(6,4))\n",
    "plt.imshow(test.T, cmap='jet')\n",
    "plt.grid(False)\n",
    "# remove ticks\n",
    "plt.xticks([])\n",
    "plt.yticks([])\n",
    "cbar = plt.colorbar()\n",
    "cbar.set_label(f'$\\\\log(\\\\tau)$', rotation=90, labelpad=8, fontsize='x-large')\n",
    "# title to the colorbar\n",
    "plt.show()\n",
    "\n",
    "# fig.savefig(os.path.join(result_path, f'clhu/imgs/sparsity_estimation_{endmember_init_method}.pdf'), dpi=300, bbox_inches='tight')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_true = dataset.A @ dataset.endmembers()\n",
    "X_hat = model(dataset.X).detach().cpu()\n",
    "A_hat = torch.softmax(model.A.detach().cpu(), dim=1)\n",
    "M_hat = sigmoid(model.ebk.detach().cpu())\n",
    "\n",
    "real_M_hat = model(M_hat).detach()\n",
    "\n",
    "import pandas as pd\n",
    "df = pd.DataFrame(columns=['Method', 'RMSE_X', 'RMSE_A', 'SAD_M'])\n",
    "df['Method'] = ['CLHU']\n",
    "df['RMSE_X'] = [rmse(X_true, X_hat, dim=None).numpy()]\n",
    "df['RMSE_A'] = [rmse(dataset.A, A_hat, dim=None).numpy()]\n",
    "\n",
    "# sad_result = sad(M_hat, dataset.endmembers()).numpy()\n",
    "sad_result = sad(real_M_hat, dataset.endmembers()).numpy()\n",
    "df['SAD_M'] = np.diagonal(sad_result).mean()\n",
    "\n",
    "# df.to_csv(os.path.join(result_path, 'clhu/metrics.csv'), index=False)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.ebk = sigmoid(model.ebk)\n",
    "x_test = sigmoid(model.ebk)\n",
    "m = model.ebk.detach()\n",
    "model.eval()\n",
    "print(x_test.min(), x_test.max())\n",
    "encoder, projection = model.encoder, model.projection\n",
    "from torch.nn.functional import normalize, softmax\n",
    "\n",
    "def __similarity(X: torch.Tensor, ebk, temperature=1e-2) -> torch.Tensor:\n",
    "        '''\n",
    "            Cosine similarity between input and endmember bank.\n",
    "\n",
    "            Parameters\n",
    "            ----------\n",
    "                x: torch.Tensor, shape=(batch_size, n_bands)\n",
    "                    input tensor.\n",
    "                \n",
    "                temperature: float, default=1e-1\n",
    "                    temperature parameter for contrastive learning.\n",
    "                \n",
    "        '''\n",
    "        bs, n_bands = X.shape\n",
    "        X = normalize(X, dim=1)\n",
    "\n",
    "        normalize_ebk = normalize(ebk.detach(), dim=1).expand(bs, -1, -1)\n",
    "        cos = torch.bmm(X.view(bs, 1, n_bands), torch.transpose(normalize_ebk, 1, 2)).squeeze()\n",
    "        # return (1 - torch.pow(cos, 2))/temperature\n",
    "        # return (torch.pow(cos, 2))/temperature\n",
    "        return torch.log(torch.pow(cos, 2))\n",
    "\n",
    "# y = projection(encoder(x_test))\n",
    "# print(softmax(__similarity(y, m, temperature=.1).detach(), dim=1))\n",
    "\n",
    "test = model(x_test)\n",
    "\n",
    "plt.plot(test[2].detach().numpy())\n",
    "plt.plot(x_test[2].detach().numpy())\n",
    "plt.show()\n",
    "\n",
    "softmax(model.A)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import sigmoid\n",
    "def test(model, dataset):\n",
    "    X = dataset.X\n",
    "    model.eval()\n",
    "    model = model.cpu()\n",
    "    \n",
    "    X_true = dataset.A @ dataset.endmembers()\n",
    "    with torch.no_grad():\n",
    "        X_hat = model(dataset.X)\n",
    "        A_hat = torch.softmax(model.A, dim=1)\n",
    "        M_hat = sigmoid(model.ebk) \n",
    "    \n",
    "    rmse_x = rmse(X_true, X_hat, dim=None).numpy()      \n",
    "    rmse_a = rmse(dataset.A, A_hat, dim=None).numpy()\n",
    "    sad_m = np.diagonal(sad(M_hat, dataset.endmembers()).numpy()).mean()\n",
    "    return rmse_x.item(), rmse_a.item(), sad_m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import train \n",
    "from HySpecLab.unmixing import ContrastiveUnmixing\n",
    "\n",
    "n_bands = dataset.n_bands\n",
    "\n",
    "batch_rmse_x = []\n",
    "batch_rmse_a = []\n",
    "batch_sad_m = []\n",
    "for i in range(10):\n",
    "    model = ContrastiveUnmixing(n_bands, n_endmembers, endmember_init=logit_endmember_init, sigma_sparsity=.25)\n",
    "    train(model, n_endmembers, dataset, n_batchs=100, n_epochs=100, lr=1e-3, similarity_weight=1, sparse_weight=.5)\n",
    "\n",
    "    rmse_x, rmse_a, sad_m = test(model, dataset)\n",
    "    batch_rmse_x.append(rmse_x)\n",
    "    batch_rmse_a.append(rmse_a)\n",
    "    batch_sad_m.append(sad_m)\n",
    "\n",
    "    print(rmse_x, rmse_a, sad_m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate dataframe\n",
    "import pandas as pd\n",
    "df = pd.DataFrame(columns=['RMSE_X', 'RMSE_A', 'SAD_M'])\n",
    "df['RMSE_X'] = batch_rmse_x\n",
    "df['RMSE_A'] = batch_rmse_a\n",
    "df['SAD_M'] = batch_sad_m\n",
    "\n",
    "# extract mean and std\n",
    "df['RMSE_X'].mean(), df['RMSE_X'].std(), df['RMSE_A'].mean(), df['RMSE_A'].std(), df['SAD_M'].mean(), df['SAD_M'].std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(os.path.join(result_path, 'clhu/metrics_{}_batch.csv'.format(endmember_init_method)), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.path.join(result_path, 'clhu/metrics_{}_batch.csv'.format(endmember_init_method))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(sigmoid(model.ebk).T.detach().cpu().numpy())\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(test.T.detach().cpu().numpy())\n",
    "plt.show()\n",
    "\n",
    "sad_m = np.diagonal(sad(test, dataset.endmembers()).detach().numpy()).mean()\n",
    "sad_m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.nn.functional import normalize   \n",
    "M = logit_endmember_init\n",
    "M_norm = normalize(M, dim=1)\n",
    "\n",
    "sim_matrix = torch.mm(M_norm, M_norm.T) / .1\n",
    "\n",
    "logit = torch.log((sim_matrix).softmax(dim=1))\n",
    "lo2 = (sim_matrix).log_softmax(dim=1)\n",
    "\n",
    "sim_matrix, torch.isclose(logit, lo2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "M_2 = M.clone()\n",
    "\n",
    "M_2[0] = M_2[2]\n",
    "M_norm = normalize(M_2, dim=1)\n",
    "\n",
    "sim_matrix = torch.mm(M_norm, M_norm.T) / .1\n",
    "\n",
    "logit = torch.log((sim_matrix).softmax(dim=1))\n",
    "lo2 = (sim_matrix).log_softmax(dim=1)\n",
    "\n",
    "sim_matrix, torch.isclose(logit, lo2)\n",
    "\n",
    "# (sim_matrix).softmax(dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.nn.functional import dropout2d\n",
    "\n",
    "X = torch.randn(1, 3, 3, 3)\n",
    "hat_X = dropout2d(X, p=.5, training=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "CLHU",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
