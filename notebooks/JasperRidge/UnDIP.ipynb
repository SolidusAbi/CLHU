{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys\n",
    "project_root_dir = os.path.join(os.getcwd(),'../..')\n",
    "if project_root_dir not in sys.path:\n",
    "    sys.path.append(project_root_dir)\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "from torch import nn\n",
    "import torch\n",
    "import config\n",
    "\n",
    "from utils import show_abundance, plot_endmembers\n",
    "# from dataset import JasperRidgeDataset\n",
    "from HySpecLab.metrics import rmse, sad\n",
    "from scipy import io as sio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataset import JasperRidge\n",
    "\n",
    "dataset = JasperRidge(config.JasperRidge_PATH)\n",
    "dataset_name = 'JasperRidge'\n",
    "wv = np.array(dataset.wv, dtype=np.uint)\n",
    "\n",
    "result_path = os.path.join(config.RESULTS_PATH, 'jasperRidge')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ground Truth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import plot_endmembers, show_abundance\n",
    "fig = plot_endmembers(dataset.endmembers(), wv, ticks_range=(0, 1), n_ticks=5)\n",
    "plt.show(fig)\n",
    "# fig.savefig(os.path.join(result_path, 'imgs/M_ref.pdf'), bbox_inches='tight')\n",
    "\n",
    "fig = show_abundance(dataset.abundance())\n",
    "plt.show(fig)\n",
    "# fig.savefig(os.path.join(result_path, 'imgs/A_ref.png'), dpi=300, bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from HySpecLab.metrics import sad\n",
    "\n",
    "def sort_endmember(endmembers, gt):\n",
    "    sad_result = sad(endmembers, gt)\n",
    "    e_idx = torch.argmin(sad_result, dim=0) # Index for reordering the ground truth\n",
    "    return e_idx, sad_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from HySpecLab.eea import VCA\n",
    "\n",
    "n_endmembers = dataset.n_endmembers\n",
    "   \n",
    "vca = VCA(n_endmembers, snr_input=-1, random_state=25)\n",
    "vca.fit(dataset.X.numpy())\n",
    "endmembers = torch.from_numpy(vca.endmembers()).float()\n",
    "e_idx, sad_result = sort_endmember(endmembers, dataset.endmembers())\n",
    "\n",
    "vca_endmember_init = endmembers[e_idx]\n",
    "vca_logit_endmember_init = torch.log((vca_endmember_init + 1e-12) / ((1-vca_endmember_init) + 1e-12))\n",
    "\n",
    "fig = plot_endmembers(vca_endmember_init, wv, ticks_range=(0, 1))\n",
    "plt.show(fig)\n",
    "\n",
    "# fig.savefig(os.path.join(result_path, 'imgs/M_vca.pdf'), bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import plot_endmembers\n",
    "from pysptools import eea\n",
    "n_endmembers = dataset.n_endmembers\n",
    "\n",
    "ee = eea.NFINDR()\n",
    "endmember = torch.from_numpy(ee.extract(dataset.image(), n_endmembers)).float()\n",
    "\n",
    "e_idx, _ = sort_endmember(endmember, dataset.endmembers())\n",
    "nfindr_endmember_init = endmember[e_idx]\n",
    "nfindr_logit_endmember_init = torch.log((nfindr_endmember_init + 1e-12) / ((1-vca_endmember_init) + 1e-12))\n",
    "\n",
    "fig = plot_endmembers(nfindr_endmember_init, wv, ticks_range=(0, 1))\n",
    "plt.show(fig)\n",
    "# fig.savefig(os.path.join(result_path, 'imgs/M_nfindr.pdf'), bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plot_endmembers(dataset.endmembers() / dataset.endmembers().max(), wv, ticks_range=(0, 1), endmember_estimation=[nfindr_endmember_init, vca_endmember_init], ee_labels=['Ground Truth', 'N-FINDR', 'VCA'])\n",
    "plt.show(fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# endmember_init_method = 'nfindr'\n",
    "# endmember_init = nfindr_endmember_init\n",
    "# logit_endmember_init = nfindr_logit_endmember_init\n",
    "\n",
    "endmember_init_method = 'vca'\n",
    "endmember_init = vca_endmember_init"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# UnDIP input\n",
    "X_tensor = torch.tensor(dataset.image().T)\n",
    "X_tensor = X_tensor.unsqueeze(0).float()\n",
    "\n",
    "from HySpecLab.unmixing import get_noise, NOISE_TYPE\n",
    "noisy_input = get_noise(X_tensor.shape[1:], batch_size = 1, noise_type=NOISE_TYPE.uniform)\n",
    "U_tensor = torch.unsqueeze(endmember_init.T, dim=0).float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from HySpecLab.unmixing import UnDIP\n",
    "\n",
    "n_bands = dataset.n_bands\n",
    "\n",
    "dims = [n_bands, 256, 256]\n",
    "skip_connection = [4, 4]\n",
    "out_channels = 60\n",
    "\n",
    "model = UnDIP(n_endmembers, out_channels, dims, skip_connection, dropout=False, batch_norm=True, activation_func=nn.LeakyReLU())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = dataset.image().T\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.imshow(X_tensor[0,25])\n",
    "plt.subplot(1, 2, 2)\n",
    "# plt.imshow(X_tensor.T[:,:,0,25])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from torchvision.utils import make_grid\n",
    "from HySpecLab.utils import fig_to_image\n",
    "from HySpecLab.unmixing.utils import restoration\n",
    "from HySpecLab.metrics import UnmixingLoss\n",
    "\n",
    "batch_size = X_tensor.shape[0]\n",
    "n_bands = X_tensor.shape[1]\n",
    "w, h = noisy_input.shape[2:]\n",
    "\n",
    "n_epoch = 3000\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3, weight_decay=1e-6)\n",
    "scheduler = torch.optim.lr_scheduler.ExponentialLR(optimizer, gamma=0.999)\n",
    "# criterion = nn.MSELoss()\n",
    "criterion = UnmixingLoss()\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = model.to(device)\n",
    "\n",
    "epoch_iterator = tqdm(\n",
    "        range(n_epoch),\n",
    "        leave=True,\n",
    "        unit=\"epoch\",\n",
    "        postfix={\"tls\": \"%.4f\" % 1},\n",
    "    )\n",
    "\n",
    "# tb_writer = SummaryWriter('logs/test')\n",
    "\n",
    "# #Endmember signal image\n",
    "# fig, ax = plt.subplots(1,1, figsize=(16,9))\n",
    "\n",
    "# labels = list(map(lambda x: 'Endmember {}'.format(x), range(len(U))))\n",
    "# ax.plot(U.T, label=labels)\n",
    "# ax.set_ylabel('Reflectance')\n",
    "\n",
    "# image = ToTensor()(fig_to_image(fig)).unsqueeze(0)\n",
    "# tb_writer.add_image('Endmembers', image, dataformats='NCHW')\n",
    "\n",
    "\n",
    "# Target Image\n",
    "# show_band_idx = np.linspace(0, X_tensor.shape[1]-1, num=16, dtype=np.int64)\n",
    "# for i in range(4):\n",
    "#     target_imgs = torch.unsqueeze(X_tensor[i, show_band_idx], dim=1)\n",
    "#     img_grid = make_grid(target_imgs)\n",
    "    # tb_writer.add_image('Target/{}'.format(i), img_grid, 0)\n",
    "\n",
    "\n",
    "noisy_input = noisy_input.to(device)\n",
    "\n",
    "for epoch in epoch_iterator:\n",
    "    abundance = model(noisy_input)\n",
    "\n",
    "    output = restoration(U_tensor.to(device), abundance)\n",
    "\n",
    "    # if epoch % 100 == 0: # Cada 100 epoch\n",
    "    #     for i in range(4):\n",
    "    #         rest_imgs = torch.unsqueeze(output[i, show_band_idx], dim=1)\n",
    "    #         img_grid = make_grid(rest_imgs)\n",
    "    #         tb_writer.add_image('Output/{}'.format(i), img_grid, epoch)\n",
    "\n",
    "    #         abundance_imgs = torch.unsqueeze(abundance[i], dim=1)\n",
    "    #         img_grid = make_grid(abundance_imgs)\n",
    "    #         tb_writer.add_image('Abundance/{}'.format(i), img_grid, epoch)\n",
    "\n",
    "    batch_loss = criterion(output, X_tensor.float().to(device))\n",
    "\n",
    "    epoch_iterator.set_postfix(tls=\"%.4f\" % np.mean(batch_loss.detach().item()))\n",
    "    # tb_writer.add_scalar('Loss', batch_loss.detach().item(), epoch)\n",
    "\n",
    "    optimizer.zero_grad()\n",
    "    batch_loss.backward()\n",
    "    optimizer.step()\n",
    "    # scheduler.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision.transforms import ToPILImage\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "A = model(noisy_input).cpu().detach()\n",
    "fig, ax = plt.subplots(1,4, figsize=(6,4))\n",
    "for i in range(len(A[0])):\n",
    "    if i >= 4:\n",
    "        break\n",
    "    \n",
    "    cax = ax[i].imshow(A[0,i].T, cmap='viridis')\n",
    "    fig.colorbar(cax, ax=ax[i])\n",
    "    ax[i].grid(False)\n",
    "    # for j in range(len(A[0])):\n",
    "    #     ax[i, j].imshow(A[i,j])\n",
    "    \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "A = (model(noisy_input).cpu().detach()[0])\n",
    "Y = torch.matmul(endmember_init.T, A.flatten(1)).numpy()\n",
    "plt.imshow(A[0], cmap='viridis')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_Y = Y.reshape(n_bands, w, h, order='F')\n",
    "plt.imshow(_Y[25], cmap='viridis')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_bands, n_row, n_col = dataset.n_bands, dataset.n_row, dataset.n_col\n",
    "Y_true =  (dataset.A @ dataset.endmembers()).numpy().reshape(n_row, n_col, n_bands).T\n",
    "plt.imshow(Y_true[25], cmap='viridis')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rmse_y = rmse(torch.tensor(_Y), torch.tensor(Y_true), dim=None)\n",
    "rmse_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "CLHU",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
