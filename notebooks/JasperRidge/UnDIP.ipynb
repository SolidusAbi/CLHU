{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys\n",
    "project_root_dir = os.path.join(os.getcwd(),'../..')\n",
    "if project_root_dir not in sys.path:\n",
    "    sys.path.append(project_root_dir)\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "from torch import nn\n",
    "import torch\n",
    "import config\n",
    "\n",
    "from utils import show_abundance, plot_endmembers\n",
    "from dataset import JasperRidge\n",
    "from HySpecLab.metrics import rmse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = JasperRidge(config.JasperRidge_PATH)\n",
    "dataset_name = 'Jasper'\n",
    "wv = np.array(dataset.wv, dtype=np.uint)\n",
    "\n",
    "result_path = os.path.join(config.RESULTS_PATH, 'jasperRidge/undip')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import plot_endmembers, show_abundance\n",
    "fig = plot_endmembers(dataset.endmembers(), wv, ticks_range=(0, 1), n_ticks=5)\n",
    "plt.show(fig)\n",
    "\n",
    "fig = show_abundance(dataset.abundance())\n",
    "plt.show(fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from HySpecLab.metrics import sad\n",
    "\n",
    "def sort_endmember(endmembers, gt):\n",
    "    sad_result = sad(endmembers, gt)\n",
    "    e_idx = torch.argmin(sad_result, dim=0) # Index for reordering the ground truth\n",
    "    return e_idx, sad_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from HySpecLab.eea import VCA\n",
    "\n",
    "n_endmembers = dataset.n_endmembers\n",
    "   \n",
    "vca = VCA(n_endmembers, snr_input=-1, random_state=25)\n",
    "vca.fit(dataset.X.numpy())\n",
    "endmembers = torch.from_numpy(vca.endmembers()).float()\n",
    "e_idx, sad_result = sort_endmember(endmembers, dataset.endmembers())\n",
    "\n",
    "vca_endmember_init = endmembers[e_idx]\n",
    "vca_logit_endmember_init = torch.log((vca_endmember_init + 1e-12) / ((1-vca_endmember_init) + 1e-12))\n",
    "\n",
    "fig = plot_endmembers(vca_endmember_init, wv, ticks_range=(0, 1))\n",
    "plt.show(fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import plot_endmembers\n",
    "from pysptools import eea\n",
    "n_endmembers = dataset.n_endmembers\n",
    "\n",
    "ee = eea.NFINDR()\n",
    "endmember = torch.from_numpy(ee.extract(dataset.image(), n_endmembers)).float()\n",
    "\n",
    "e_idx, _ = sort_endmember(endmember, dataset.endmembers())\n",
    "nfindr_endmember_init = endmember[e_idx]\n",
    "nfindr_logit_endmember_init = torch.log((nfindr_endmember_init + 1e-12) / ((1-vca_endmember_init) + 1e-12))\n",
    "\n",
    "fig = plot_endmembers(nfindr_endmember_init, wv, ticks_range=(0, 1))\n",
    "plt.show(fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plot_endmembers(dataset.endmembers() / dataset.endmembers().max(), wv, ticks_range=(0, 1), endmember_estimation=[nfindr_endmember_init, vca_endmember_init], ee_labels=['Ground Truth', 'N-FINDR', 'VCA'])\n",
    "plt.show(fig)\n",
    "fig.savefig(os.path.join(result_path, 'imgs/M_init.pdf'), bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "endmember_init_method = 'nfindr'\n",
    "endmember_init = nfindr_endmember_init\n",
    "\n",
    "# endmember_init_method = 'vca'\n",
    "# endmember_init = vca_endmember_init"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision.transforms import Resize\n",
    "\n",
    "Y = np.transpose(dataset.image(), (2, 0, 1))\n",
    "X_tensor = torch.from_numpy(Y).float().unsqueeze(0)\n",
    "\n",
    "from HySpecLab.unmixing import get_noise, NOISE_TYPE\n",
    "noisy_input = get_noise(X_tensor.shape[1:], batch_size = X_tensor.shape[0], noise_type=NOISE_TYPE.uniform)\n",
    "U_tensor = torch.unsqueeze(endmember_init.T, dim=0).float()\n",
    "\n",
    "print('Z shape: {}'.format(noisy_input.shape))\n",
    "print('HyperCube shape: {}'.format(X_tensor.shape))\n",
    "print('Endmember shape: {}'.format(U_tensor.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from HySpecLab.unmixing import UnDIP\n",
    "\n",
    "n_bands = X_tensor.shape[1]\n",
    "n_endmembers = U_tensor.shape[-1]\n",
    "\n",
    "dims = [n_bands, 256, 256]\n",
    "skip_connection = [6, 6]\n",
    "out_channels = 64\n",
    "\n",
    "model = UnDIP(n_endmembers, out_channels, dims, skip_connection, dropout=True, batch_norm=True, activation_func=nn.LeakyReLU())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "from HySpecLab.unmixing.utils import restoration\n",
    "from HySpecLab.metrics import UnmixingLoss\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "n_epoch = 5000\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3, weight_decay=1e-6)\n",
    "scheduler = torch.optim.lr_scheduler.ExponentialLR(optimizer, gamma=0.999)\n",
    "criterion = UnmixingLoss()\n",
    "\n",
    "model.train()\n",
    "model = model.to(device)\n",
    "\n",
    "epoch_iterator = tqdm(\n",
    "        range(n_epoch),\n",
    "        leave=True,\n",
    "        unit=\"epoch\",\n",
    "        postfix={\"tls\": \"%.4f\" % 1},\n",
    "    )\n",
    "\n",
    "noisy_input = noisy_input.to(device)\n",
    "\n",
    "for epoch in epoch_iterator:\n",
    "    abundance = model(noisy_input)\n",
    "\n",
    "    output = restoration(U_tensor.to(device), abundance)\n",
    "\n",
    "    batch_loss = criterion(output, X_tensor.float().to(device))\n",
    "\n",
    "    epoch_iterator.set_postfix(tls=\"%.4f\" % np.mean(batch_loss.detach().item()))\n",
    "    optimizer.zero_grad()\n",
    "    batch_loss.backward()\n",
    "    optimizer.step()\n",
    "    scheduler.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    abundance = model(noisy_input).detach().cpu()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_abundance = abundance[0].detach().cpu().numpy().transpose(1, 2, 0)\n",
    "fig = show_abundance(_abundance, transpose=False)\n",
    "fig.savefig(os.path.join(result_path, f'imgs/A_estimation_{endmember_init_method}.pdf'), bbox_inches='tight')\n",
    "plt.show(fig)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision.transforms import Resize, InterpolationMode\n",
    "\n",
    "A = torch.tensor(np.transpose(dataset.abundance().numpy(), (2,0,1))).cpu()\n",
    "A_hat = abundance[0].cpu()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "M_hat = endmember_init\n",
    "M = dataset.endmembers()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_true = dataset.A @ dataset.endmembers()\n",
    "X_true = X_true.T.reshape(198, 100, 100)\n",
    "\n",
    "X_hat = restoration(U_tensor, abundance)\n",
    "X_hat = X_hat[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.DataFrame(columns=['Method', 'RMSE_X', 'RMSE_A', 'SAD_M'])\n",
    "df['Method'] = ['CLHU']\n",
    "df['RMSE_X'] = [rmse(X_true, X_hat, dim=None).numpy()]\n",
    "df['RMSE_A'] = [rmse(A, A_hat, dim=None).numpy()]\n",
    "\n",
    "sad_result = sad(M_hat, dataset.endmembers()).numpy()\n",
    "df['SAD_M'] = np.diagonal(sad_result).mean()\n",
    "\n",
    "df.to_csv(os.path.join(result_path, f'metrics_{endmember_init_method}.csv'), index=False)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Batch test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(model, dataset, noisy_input, U):\n",
    "    model.eval()\n",
    "    model = model.cpu()\n",
    "    with torch.no_grad():\n",
    "        abundance = model(noisy_input.cpu()).detach().cpu()\n",
    "\n",
    "    \n",
    "    A = torch.tensor(np.transpose(dataset.abundance(), (2,0,1))).cpu()\n",
    "    A_hat = abundance[0].cpu()\n",
    "\n",
    "    M_hat = U[0].T\n",
    "    M = dataset.endmembers()\n",
    "\n",
    "    X_true = dataset.A @ dataset.endmembers()\n",
    "    X_true = X_true.T.reshape(198, 100, 100)\n",
    "\n",
    "    X_hat = restoration(U, abundance)\n",
    "    X_hat = X_hat[0]\n",
    "    \n",
    "    rmse_x = rmse(X_true, X_hat, dim=None).numpy()\n",
    "    rmse_a = rmse(A, A_hat, dim=None).numpy()\n",
    "    sad_m = np.diagonal(sad(M, M_hat).numpy()).mean()\n",
    "    return rmse_x.item(), rmse_a.item(), sad_m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "from HySpecLab.unmixing.utils import restoration\n",
    "from HySpecLab.metrics import UnmixingLoss\n",
    "\n",
    "def train(model, X_tensor, U_tensor, noisy_input):\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "    n_epoch = 5000\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=1e-3, weight_decay=1e-6)\n",
    "    scheduler = torch.optim.lr_scheduler.ExponentialLR(optimizer, gamma=0.999)\n",
    "    criterion = UnmixingLoss()\n",
    "\n",
    "    model.train()\n",
    "    model = model.to(device)\n",
    "    noisy_input = noisy_input.to(device)\n",
    "\n",
    "    epoch_iterator = tqdm(\n",
    "            range(n_epoch),\n",
    "            leave=True,\n",
    "            unit=\"epoch\",\n",
    "            postfix={\"tls\": \"%.4f\" % 1},\n",
    "        )\n",
    "\n",
    "    for _ in epoch_iterator:\n",
    "        abundance = model(noisy_input)\n",
    "\n",
    "        output = restoration(U_tensor.to(device), abundance)\n",
    "\n",
    "        batch_loss = criterion(output, X_tensor.float().to(device))\n",
    "\n",
    "        epoch_iterator.set_postfix(tls=\"%.4f\" % np.mean(batch_loss.detach().item()))\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        batch_loss.backward()\n",
    "        optimizer.step()\n",
    "        scheduler.step()\n",
    "\n",
    "    noisy_input = noisy_input.cpu()\n",
    "    return model.cpu()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from HySpecLab.unmixing import UnDIP\n",
    "\n",
    "n_bands = X_tensor.shape[1]\n",
    "n_endmembers = U_tensor.shape[-1]\n",
    "dims = [n_bands, 256, 256]\n",
    "skip_connection = [4, 4]\n",
    "out_channels = 256\n",
    "\n",
    "batch_rmse_x = []\n",
    "batch_rmse_a = []\n",
    "batch_sad_m = []\n",
    "for i in range(10):\n",
    "    model = UnDIP(n_endmembers, out_channels, dims, skip_connection, dropout=True, batch_norm=True, activation_func=nn.LeakyReLU())\n",
    "\n",
    "    model = train(model, X_tensor, U_tensor, noisy_input)\n",
    "    rmse_x, rmse_a, sad_m = test(model, dataset, noisy_input, U_tensor)\n",
    "    batch_rmse_x.append(rmse_x)\n",
    "    batch_rmse_a.append(rmse_a)\n",
    "    batch_sad_m.append(sad_m)\n",
    "\n",
    "    print(rmse_x, rmse_a, sad_m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.DataFrame(columns=['RMSE_X', 'RMSE_A', 'SAD_M'])\n",
    "df['RMSE_X'] = batch_rmse_x\n",
    "df['RMSE_A'] = batch_rmse_a\n",
    "df['SAD_M'] = batch_sad_m\n",
    "\n",
    "# extract mean and std\n",
    "df.to_csv(os.path.join(result_path, 'metrics_{}_batch.csv'.format(endmember_init_method)), index=False)\n",
    "print(df['RMSE_X'].mean(), df['RMSE_X'].std(), df['RMSE_A'].mean(), df['RMSE_A'].std(), df['SAD_M'].mean(), df['SAD_M'].std())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DeepLearning",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
