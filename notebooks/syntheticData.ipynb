{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys\n",
    "project_root_dir = os.path.join(os.getcwd(),'..')\n",
    "if project_root_dir not in sys.path:\n",
    "    sys.path.append(project_root_dir)\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import config\n",
    "\n",
    "plt.style.use('seaborn-v0_8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_path = os.path.join(config.RESULTS_PATH, 'syntheticData')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset\n",
    "from dataset import HSIDataset\n",
    "from scipy import io as sio\n",
    "\n",
    "class SyntheticDataset(HSIDataset):\n",
    "    def __init__(self, root_dir, transform=None):\n",
    "        super(SyntheticDataset, self).__init__()\n",
    "        data = sio.loadmat(os.path.join(root_dir, \"Y.mat\"))\n",
    "\n",
    "        self.n_row, self.n_col , self.n_bands = data['nRow'].item(), data['nCol'].item(), data['nBand'].item()\n",
    "        self.X = np.abs(data['Y'].T) # Because of the noise, there are negative values\n",
    "        self.X = self.X.reshape(self.n_row, self.n_col, -1)\n",
    "        self.X = self.preprocessing(self.X, max_value=1).reshape(-1, self.X.shape[-1]) # (nRow*nCol, nBand)\n",
    "\n",
    "        self.E = sio.loadmat(os.path.join(root_dir, \"M.mat\"))['M_avg'].T\n",
    "        self.A = sio.loadmat(os.path.join(root_dir, \"A.mat\"))['A'].T\n",
    "\n",
    "        self.X = torch.tensor(self.X, dtype=torch.float32)\n",
    "        self.E = torch.tensor(self.E, dtype=torch.float32)\n",
    "        self.A = torch.tensor(self.A, dtype=torch.float32)\n",
    "        self.n_endmembers = self.E.shape[0]\n",
    "\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.n_row * self.n_col\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        sample = self.X[idx]\n",
    "        if self.transform:\n",
    "            sample = self.transform(sample)\n",
    "\n",
    "        return sample\n",
    "\n",
    "    def endmembers(self):\n",
    "        return self.E\n",
    "\n",
    "    def abundance(self):\n",
    "        return self.A.numpy().reshape(self.n_row, self.n_col, -1)\n",
    "\n",
    "    def image(self):\n",
    "        return self.X.numpy().reshape(self.n_row, self.n_col, -1, order='F')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from HySpecLab.metrics import UnmixingLoss, NormalizedEntropy\n",
    "from HySpecLab.metrics.regularization import SimplexVolumeLoss, SimilarityLoss\n",
    "\n",
    "from HySpecLab.unmixing import ContrastiveUnmixing\n",
    "from tqdm import tqdm\n",
    "from torch.optim.lr_scheduler import StepLR\n",
    "from torch import sigmoid\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "def train(model:nn.Module, n_endmembers:int, dataset:Dataset, n_batchs:int = 64, n_epochs:int = 100, lr=1e-3, simplex_weight=1e-5):\n",
    "    device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "    model = model.to(device)\n",
    "    model.train()\n",
    "\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "    # optimizer = torch.optim.SGD(model.parameters(), lr=lr)\n",
    "    criterion = UnmixingLoss() \n",
    "    volume_reg = SimplexVolumeLoss(dataset[:], n_endmembers).to(device)\n",
    "    similarity_reg = SimilarityLoss(n_endmembers, temperature=.1, reduction='mean')\n",
    "    vol_reg_norm = volume_reg(torch.sigmoid(model.ebk.detach()))\n",
    "    print(vol_reg_norm)\n",
    "    \n",
    "\n",
    "\n",
    "    dataloader = DataLoader(dataset, batch_size=int(len(dataset)/n_batchs), shuffle=True)\n",
    "\n",
    "    epoch_iterator = tqdm(\n",
    "            range(n_epochs),\n",
    "            leave=True,\n",
    "            unit=\"epoch\",\n",
    "            postfix={\"tls\": \"%.4f\" % -1},\n",
    "        )\n",
    "\n",
    "    similarity_weight = 5e-1\n",
    "\n",
    "    scaler = torch.cuda.amp.GradScaler()\n",
    "\n",
    "    for epoch in epoch_iterator:\n",
    "        epoch_loss = 0.\n",
    "        for i, (x) in enumerate(dataloader):\n",
    "            x = x.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            y = model(x)\n",
    "            loss = criterion(y, x) + simplex_weight*(volume_reg(sigmoid(model.ebk))/vol_reg_norm) + similarity_weight*similarity_reg(model.ebk)\n",
    "            epoch_loss += loss.detach().item()\n",
    "\n",
    "            scaler.scale(loss).backward()\n",
    "            scaler.step(optimizer)\n",
    "            scaler.update()\n",
    "            \n",
    "        epoch_iterator.set_postfix(tls=\"%.4f\" % (epoch_loss/(i+1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import io as sio\n",
    "\n",
    "synthetic_data_path = \"/home/abian/Data/Dataset/HSI/SyntheticData/\"\n",
    "data = sio.loadmat(synthetic_data_path + \"Y.mat\")\n",
    "M = sio.loadmat(synthetic_data_path + \"M.mat\")['M_avg']\n",
    "A = sio.loadmat(synthetic_data_path + \"A.mat\")['A'].T\n",
    "\n",
    "X = data['Y'].T\n",
    "X = X.reshape(data['nRow'].item(), data['nCol'].item(), -1, order='F')\n",
    "A = A.reshape(data['nRow'].item(), data['nCol'].item(), -1, order='F')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Image to RGB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = SyntheticDataset(synthetic_data_path, transform=None)\n",
    "\n",
    "# matlab_data = {\n",
    "#     'X': dataset.image(),\n",
    "#     'n_endmembers': dataset.n_endmembers,\n",
    "#     'nRow': dataset.n_row,\n",
    "#     'nCol': dataset.n_col,\n",
    "#     'nBand': dataset.n_bands\n",
    "# }\n",
    "\n",
    "# sio.savemat(os.path.join(result_path, 'data/input.mat'), matlab_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "jasper_wv = np.linspace(380, 2500, 224) # 224 bands from 380 to 2500 nm\n",
    "\n",
    "data = sio.loadmat(os.path.join(config.JasperRidge_PATH, 'jasperRidge2_R198.mat'))\n",
    "selected_bands = data['SlectBands'].squeeze()\n",
    "selected_jasper_wv = jasper_wv[selected_bands].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from HSI2RGB import HSI2RGB\n",
    "\n",
    "# Use the D65 illuminant\n",
    "illuminant = 65\n",
    "\n",
    "# Do minor thresholding\n",
    "threshold = 0.02\n",
    "X = dataset.image()\n",
    "(ydim, xdim, zdim) = X.shape\n",
    "\n",
    "# Reorder data so that each column holds the spectra of of one pixel\n",
    "HSI_data = np.reshape(X, [-1,zdim])\n",
    "rgb = HSI2RGB(selected_jasper_wv, HSI_data, xdim, ydim, illuminant, threshold)\n",
    "\n",
    "fig = plt.figure(figsize=(7,5))\n",
    "plt.subplot(3,4,1)\n",
    "plt.imshow(rgb)\n",
    "plt.axis('off')\n",
    "plt.show()\n",
    "\n",
    "fig.savefig(os.path.join(result_path, 'imgs/synthetic_rgb.png'), dpi=300, bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import plot_endmembers, show_abundance\n",
    "fig = plot_endmembers(dataset.endmembers(), ticks_range=(0, .7))\n",
    "plt.show(fig)\n",
    "fig.savefig(os.path.join(result_path, 'imgs/E_ref.pdf'), bbox_inches='tight')\n",
    "\n",
    "fig = show_abundance(dataset.abundance())\n",
    "fig.savefig(os.path.join(result_path, 'imgs/A_ref.png'), dpi=300, bbox_inches='tight')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Endmember estimation"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## VCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from HySpecLab.eea import VCA\n",
    "_X = X.reshape(-1, X.shape[-1])\n",
    "n_endmembers = 3\n",
    "vca = VCA(n_endmembers, snr_input=30, random_state=25)\n",
    "vca.fit(_X)\n",
    "endmembers = vca.endmembers()\n",
    "\n",
    "plot_endmembers(endmembers, ticks_range=(0, .7))\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NFINDR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import plot_endmembers\n",
    "from pysptools import eea\n",
    "n_endmembers = dataset.n_endmembers\n",
    "\n",
    "ee = eea.NFINDR()\n",
    "endmember = ee.extract(X, n_endmembers)\n",
    "endmember_init = torch.from_numpy(endmember).float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from HySpecLab.metrics import sad\n",
    "\n",
    "sad_result = sad(endmember_init, dataset.endmembers())\n",
    "e_idx = torch.argmin(sad_result, dim=0) # Index for reordering the ground truth\n",
    "endmember_init = endmember_init[e_idx]\n",
    "logit_endmember_init = torch.log((endmember_init / (1-endmember_init) + 1e-12))\n",
    "\n",
    "fig = plot_endmembers(endmember_init, ticks_range=(0, .7))\n",
    "plt.show(fig)\n",
    "fig.savefig(os.path.join(result_path, 'imgs/E_nfindr_est.pdf'), bbox_inches='tight')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_bands = dataset.n_bands\n",
    "model = ContrastiveUnmixing(n_bands, n_endmembers, endmember_init=logit_endmember_init)\n",
    "train(model, n_endmembers, dataset, n_batchs=50, n_epochs=50, lr=1e-3, simplex_weight=1e-2)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## save model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), os.path.join(result_path, 'weights/clhu.pth'))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load model\n",
    "model = ContrastiveUnmixing(dataset.n_bands, dataset.n_endmembers)\n",
    "\n",
    "model.load_state_dict(torch.load(os.path.join(result_path, 'weights/clhu.pth')))\n",
    "model = model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = UnmixingLoss()\n",
    "entropy_reg  = NormalizedEntropy(S=dataset.n_endmembers)\n",
    "volume_reg = SimplexVolumeLoss(dataset[:], dataset.n_endmembers)\n",
    "similarity_reg = SimilarityLoss(dataset.n_endmembers, temperature=.1, reduction='mean')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_X = dataset.X\n",
    "\n",
    "model.eval()\n",
    "model = model.cpu()\n",
    "reconstruc = model(_X)\n",
    "with torch.no_grad():\n",
    "    print(criterion(reconstruc, _X).cpu(), entropy_reg(model.A).cpu(), volume_reg(sigmoid(model.ebk)).cpu(),\n",
    "         similarity_reg(sigmoid(model.ebk)).cpu())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "volume_reg(endmember_init), similarity_reg(endmember_init)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ebk = sigmoid(model.ebk).detach().cpu()\n",
    "\n",
    "fig = plot_endmembers(ebk, ticks_range=(0, .7))\n",
    "plt.show(fig)\n",
    "# fig.savefig(os.path.join(result_path, 'imgs/E_clhu_est.pdf'), bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.nn.functional import softmax\n",
    "from utils import show_abundance\n",
    "\n",
    "test = softmax(model.A.detach(), dim=1).cpu().numpy().reshape(dataset.n_row, dataset.n_col, -1)\n",
    "\n",
    "fig = show_abundance(test)\n",
    "plt.show(fig)\n",
    "\n",
    "# fig.savefig(os.path.join(result_path, 'imgs/A_clhu_est.png'), dpi=300, bbox_inches='tight')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = model(_X)\n",
    "y = y.detach().cpu()\n",
    "\n",
    "from HySpecLab.metrics import rmse\n",
    "rmse(y, _X, dim=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from HySpecLab.metrics import sad\n",
    "\n",
    "sad_result = sad(ebk, dataset.endmembers())\n",
    "print(sad_result)\n",
    "np.argmin(sad_result, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sad_result = sad(endmember_init, dataset.endmembers())\n",
    "print(sad_result)\n",
    "np.argmin(sad_result, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = sio.loadmat(os.path.join(synthetic_data_path, 'A_est', 'FCLS.mat'))['A'].T\n",
    "# from utils import plot_abundance\n",
    "A = test.reshape(50,50,-1,order='C')\n",
    "fig = show_abundance(A)\n",
    "plt.show(fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = sio.loadmat(os.path.join(synthetic_data_path, 'M_est', 'MESMA.mat'))\n",
    "M = data['M']\n",
    "plt.plot(M[:,:,2000])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(M[:,:,1000])\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "CLHU",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
