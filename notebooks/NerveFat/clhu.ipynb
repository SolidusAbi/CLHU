{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys\n",
    "project_root_dir = os.path.join(os.getcwd(),'../..')\n",
    "if project_root_dir not in sys.path:\n",
    "    sys.path.append(project_root_dir)\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "from torch import nn\n",
    "import torch\n",
    "import config\n",
    "\n",
    "from utils import show_abundance, plot_endmembers\n",
    "from HySpecLab.metrics import rmse, sad\n",
    "from scipy import io as sio"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataset import NerveFat\n",
    "dataset = NerveFat(root_dir=config.NerveFat_PATH)\n",
    "result_path = os.path.join(config.RESULTS_PATH, 'nerveFat')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocessing(X:np.ndarray):\n",
    "        '''\n",
    "            Preprocessing the dataset for removing high-frequency noise. \n",
    "            This preprocessing consists of three steps:\n",
    "                1. Median filter in the spatial domain.\n",
    "                2. Moving average filter in the spectral domain. (No!)\n",
    "                3. Normalization of the data.\n",
    "\n",
    "            Parameters\n",
    "            ----------\n",
    "                X : np.ndarray, shape (nRow, nCol, nBand)\n",
    "                    HSI Cube.\n",
    "        '''\n",
    "        from skimage.filters import median\n",
    "        from utils import moving_average\n",
    "\n",
    "        # X = median(X, footprint=np.ones((3,3,1)))\n",
    "        # X = moving_average(X.reshape(-1, X.shape[-1]), 5, padding_size=4).reshape(X.shape[0], X.shape[1], -1)\n",
    "        return X\n",
    "\n",
    "X_filtered = preprocessing(dataset.X.reshape(dataset.n_row, dataset.n_col, -1))\n",
    "dataset.X = torch.tensor(X_filtered.reshape(-1, X_filtered.shape[-1])).float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# matlab_data = {\n",
    "#     'X': dataset.image(),\n",
    "#     'n_endmembers': dataset.n_endmembers,\n",
    "#     'nRow': dataset.n_row,\n",
    "#     'nCol': dataset.n_col,\n",
    "#     'nBand': dataset.n_bands\n",
    "# }\n",
    "\n",
    "# sio.savemat(os.path.join(result_path, 'matlab/input.mat'), matlab_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = dataset.image()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_endmembers = 3\n",
    "\n",
    "from HySpecLab.metrics import sad\n",
    "\n",
    "def sort_endmember(endmembers, gt):\n",
    "    sad_result = sad(endmembers, gt)\n",
    "    e_idx = torch.argmin(sad_result, dim=0) # Index for reordering the ground truth\n",
    "    return endmembers[e_idx], e_idx, sad_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from HySpecLab.eea import VCA\n",
    "   \n",
    "vca = VCA(n_endmembers, snr_input=1, random_state=42)\n",
    "vca.fit(dataset.X.numpy())\n",
    "endmembers = torch.from_numpy(vca.endmembers()).float()\n",
    "\n",
    "vca_endmember_init = endmembers\n",
    "vca_logit_endmember_init = torch.log((vca_endmember_init + 1e-12) / ((1-vca_endmember_init) + 1e-12))\n",
    "\n",
    "fig = plot_endmembers(vca_endmember_init, ticks_range=(0, 1))\n",
    "plt.show(fig)\n",
    "\n",
    "fig.savefig(os.path.join(result_path, 'imgs/M_vca.pdf'), bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import plot_endmembers\n",
    "from pysptools import eea\n",
    "\n",
    "ee = eea.NFINDR()\n",
    "endmember = torch.from_numpy(ee.extract(dataset.image(), n_endmembers)).float()\n",
    "\n",
    "nfindr_endmember_init = endmember\n",
    "nfindr_logit_endmember_init = torch.log((nfindr_endmember_init + 1e-12) / ((1-nfindr_endmember_init) + 1e-12))\n",
    "\n",
    "nfindr_endmember_init, _, _ = sort_endmember(nfindr_endmember_init, vca_endmember_init)\n",
    "nfindr_logit_endmember_init = torch.log((nfindr_endmember_init + 1e-12) / ((1-nfindr_endmember_init) + 1e-12))\n",
    "\n",
    "fig = plot_endmembers(nfindr_endmember_init, ticks_range=(0, 1))\n",
    "plt.show(fig)\n",
    "fig.savefig(os.path.join(result_path, 'imgs/M_nfindr.pdf'), bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# endmember_init_method = 'nfindr'\n",
    "# endmember_init = nfindr_endmember_init\n",
    "# logit_endmember_init = nfindr_logit_endmember_init\n",
    "\n",
    "endmember_init_method = 'vca'\n",
    "endmember_init = vca_endmember_init\n",
    "logit_endmember_init = vca_logit_endmember_init"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import train \n",
    "from HySpecLab.unmixing import ContrastiveUnmixing\n",
    "\n",
    "n_bands = dataset.n_bands\n",
    "model = ContrastiveUnmixing(n_bands, n_endmembers, endmember_init=logit_endmember_init, sigma_sparsity=.5)\n",
    "train(model, n_endmembers, dataset, n_batchs=50, n_epochs=100, lr=1e-3, similarity_weight=1, sparse_weight=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "_ = model(dataset.X.cuda())\n",
    "print(model.sparse_gate.variational_parameter().flatten())\n",
    "print(model.sparse_gate.variational_parameter().flatten().mean())\n",
    "print(model.sparse_gate.variational_parameter().flatten().min())\n",
    "print(model.sparse_gate.regularize())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# torch.save(model.state_dict(), os.path.join(result_path, 'clhu/weights/clhu.pth'))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from HySpecLab.unmixing import ContrastiveUnmixing\n",
    "\n",
    "# # load model\n",
    "# model = ContrastiveUnmixing(dataset.n_bands, n_endmembers)\n",
    "\n",
    "# model.load_state_dict(torch.load(os.path.join(result_path, 'clhu/weights/clhu.pth')))\n",
    "model = model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "from HySpecLab.metrics.regularization import SimplexVolumeLoss, SimilarityLoss\n",
    "from HySpecLab.metrics import UnmixingLoss, NormalizedEntropy\n",
    "\n",
    "criterion = UnmixingLoss()\n",
    "entropy_reg  = NormalizedEntropy(S=n_endmembers)\n",
    "volume_reg = SimplexVolumeLoss(dataset[:], n_endmembers)\n",
    "similarity_reg = SimilarityLoss(n_endmembers, temperature=.1, reduction='mean')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import sigmoid \n",
    "_X = dataset.X\n",
    "\n",
    "model.eval()\n",
    "model = model.cpu()\n",
    "reconstruc = model(_X)\n",
    "with torch.no_grad():\n",
    "    print(criterion(reconstruc, _X).cpu(), entropy_reg(model.A).cpu(), volume_reg(sigmoid(model.ebk)).cpu(),\n",
    "         similarity_reg(model.ebk).cpu())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "volume_reg(endmember_init), similarity_reg(logit_endmember_init)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ebk = torch.sigmoid(model.ebk).detach()\n",
    "fig = plot_endmembers(ebk, wv=dataset.wv, figsize=(6,4), ticks_range=(0, .92), endmember_estimation=[vca_endmember_init, nfindr_endmember_init], ee_labels=['CLHU', 'VCA', 'N-FINDR'])\n",
    "# fig = plot_endmembers(ebk, wv=dataset.wv, ticks_range=(0, .8))\n",
    "plt.show(fig)\n",
    "\n",
    "# fig.savefig(os.path.join(result_path, 'imgs/M_clhu.pdf'), bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.nn.functional import softmax\n",
    "test = softmax(model.A.detach(), dim=1).cpu().numpy().reshape(dataset.n_row, dataset.n_col, -1, order='F')\n",
    "\n",
    "fig = show_abundance(test)\n",
    "plt.show(fig)\n",
    "\n",
    "# fig.savefig(os.path.join(result_path, 'imgs/A_clhu.png'), dpi=300, bbox_inches='tight')\n",
    "# fig.savefig(os.path.join(result_path, 'imgs/A_clhu.pdf'), bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test = model._sparse.detach().cpu().numpy().reshape(dataset.n_row, dataset.n_col)\n",
    "test = model.sparse_gate.variational_parameter().detach().cpu().numpy().reshape(dataset.n_row, dataset.n_col)\n",
    "test = np.log(test)\n",
    "\n",
    "fig = plt.figure(figsize=(6,4))\n",
    "plt.imshow(test, cmap='jet')\n",
    "# # set \"log(\\rho)\" in colorbar\n",
    "cbar = plt.colorbar()\n",
    "cbar.set_label(r'$\\log(\\rho)$', labelpad=2, fontsize=14)\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "M = sigmoid(model.ebk).detach()\n",
    "M_hat = model(M).detach().cpu()\n",
    "\n",
    "fig = plot_endmembers(M_hat, wv=dataset.wv, ticks_range=(0, .9), endmember_estimation=[M], ee_labels=['Reconstructed', 'M'])\n",
    "\n",
    "plt.show(fig)\n",
    "\n",
    "torch.softmax(model.A, dim=1).detach()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multiple Configurations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.nn.functional import softmax\n",
    "def save_result(model, dataset, result_dir):\n",
    "    model = model.eval()\n",
    "    model = model.cpu()\n",
    "\n",
    "    X = dataset.X\n",
    "    _ = model(X)\n",
    "    \n",
    "    M = torch.sigmoid(model.ebk).detach()\n",
    "    fig = plot_endmembers(M, wv=dataset.wv, figsize=(6,4), ticks_range=(0, .92), endmember_estimation=[vca_endmember_init, nfindr_endmember_init], ee_labels=['CLHU', 'VCA', 'N-FINDR'])\n",
    "    fig.savefig(os.path.join(result_dir, 'M_clhu.pdf'), bbox_inches='tight')\n",
    "    plt.close(fig)\n",
    "    \n",
    "    A = softmax(model.A.detach(), dim=1).cpu().numpy().reshape(dataset.n_row, dataset.n_col, -1, order='F')\n",
    "    fig = show_abundance(A)\n",
    "    fig.savefig(os.path.join(result_dir, 'A_clhu.pdf'), bbox_inches='tight')\n",
    "    plt.close(fig)\n",
    "    \n",
    "    sparse = model.sparse_gate.variational_parameter().detach().cpu().numpy().reshape(dataset.n_row, dataset.n_col)\n",
    "    sparse = np.log(sparse)\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=(6,4))\n",
    "    im = ax.imshow(sparse, cmap='jet')\n",
    "    cbar = plt.colorbar(im)\n",
    "    cbar.ax.tick_params(labelsize=12)\n",
    "    cbar.set_label(r'$\\log(\\rho)$', labelpad=2, fontsize=14)\n",
    "    plt.axis('off')\n",
    "    plt.savefig(os.path.join(result_dir, 'sparse_clhu.pdf'), bbox_inches='tight')\n",
    "    plt.close(fig)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [00:16<00:00,  3.05epoch/s, tls=0.0535]\n",
      "100%|██████████| 50/50 [00:16<00:00,  2.99epoch/s, tls=0.0614]\n",
      "100%|██████████| 50/50 [00:17<00:00,  2.94epoch/s, tls=0.0699]\n",
      "100%|██████████| 50/50 [00:17<00:00,  2.91epoch/s, tls=0.1275]\n",
      "100%|██████████| 50/50 [00:16<00:00,  2.99epoch/s, tls=0.0752]\n",
      "100%|██████████| 50/50 [00:16<00:00,  3.05epoch/s, tls=0.0767]\n",
      "100%|██████████| 50/50 [00:16<00:00,  3.06epoch/s, tls=0.0903]\n",
      "100%|██████████| 50/50 [00:16<00:00,  2.98epoch/s, tls=0.1291]\n",
      "100%|██████████| 50/50 [00:16<00:00,  3.05epoch/s, tls=0.1139]\n",
      "100%|██████████| 50/50 [00:16<00:00,  3.00epoch/s, tls=0.1087]\n",
      "100%|██████████| 50/50 [00:17<00:00,  2.93epoch/s, tls=0.1108]\n",
      "100%|██████████| 50/50 [00:16<00:00,  3.05epoch/s, tls=0.1490]\n",
      "100%|██████████| 50/50 [00:16<00:00,  2.95epoch/s, tls=0.5171]\n",
      "100%|██████████| 50/50 [00:16<00:00,  2.98epoch/s, tls=0.1599]\n",
      "100%|██████████| 50/50 [00:16<00:00,  2.95epoch/s, tls=0.1689]\n",
      "100%|██████████| 50/50 [00:17<00:00,  2.90epoch/s, tls=0.2069]\n",
      "100%|██████████| 50/50 [00:16<00:00,  3.04epoch/s, tls=0.2306]\n",
      "100%|██████████| 50/50 [00:17<00:00,  2.93epoch/s, tls=0.2488]\n",
      "100%|██████████| 50/50 [00:16<00:00,  3.06epoch/s, tls=0.2720]\n",
      "100%|██████████| 50/50 [00:16<00:00,  2.98epoch/s, tls=0.3108]\n",
      "100%|██████████| 50/50 [00:17<00:00,  2.86epoch/s, tls=0.3703]\n",
      "100%|██████████| 50/50 [00:16<00:00,  2.95epoch/s, tls=0.3899]\n",
      "100%|██████████| 50/50 [00:17<00:00,  2.89epoch/s, tls=0.4425]\n",
      "100%|██████████| 50/50 [00:16<00:00,  3.00epoch/s, tls=0.4459]\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from sklearn.model_selection import ParameterGrid\n",
    "from utils import train \n",
    "from HySpecLab.unmixing import ContrastiveUnmixing\n",
    "\n",
    "\n",
    "param_grid = {\n",
    "    'sigma': [.05, .1, .25, .5],\n",
    "    'lambda': [0, .05, .1, .25, .5, 1],\n",
    "}\n",
    "\n",
    "\n",
    "n_bands = dataset.n_bands\n",
    "for params in ParameterGrid(param_grid):\n",
    "    sigma = params['sigma']\n",
    "    lambda_ = params['lambda']\n",
    "\n",
    "    result_dir = os.path.join(result_path, f'clhu/sparse_no_normalized/sigma_{sigma}/lambda_{lambda_}')\n",
    "    os.makedirs(result_dir, exist_ok=True)\n",
    "\n",
    "    model = ContrastiveUnmixing(n_bands, n_endmembers, endmember_init=logit_endmember_init, sigma_sparsity=sigma)\n",
    "    train(model, n_endmembers, dataset, n_batchs=50, n_epochs=50, lr=1e-3, similarity_weight=1, sparse_weight=lambda_)\n",
    "    save_result(model, dataset, result_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch \n",
    "n_endmembers=3\n",
    "torch.vstack((torch.zeros((n_endmembers-1,)), torch.eye(n_endmembers-1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "X = dataset.X\n",
    "mu = X.reshape(-1, X.shape[-1]).mean(axis=0, keepdims=True).T\n",
    "U = PCA(n_components=n_endmembers-1, random_state=42).fit(X.reshape(-1, X.shape[-1])).components_.T # (bands, endmembers-1)\n",
    "U = torch.tensor(U, dtype=torch.float32)\n",
    "mu.shape, U.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(U.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "B = torch.vstack((torch.zeros((n_endmembers-1,)), torch.eye(n_endmembers-1)))\n",
    "C = torch.zeros((n_endmembers, n_endmembers))\n",
    "C[0, :] = 1\n",
    "print(B)\n",
    "print(C)\n",
    "Z = C+B@U.T@(vca_endmember_init.T-mu)\n",
    "print(Z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_endmembers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "CLHU",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
