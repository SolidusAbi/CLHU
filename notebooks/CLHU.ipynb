{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys\n",
    "project_root_dir = os.path.join(os.getcwd(),'..')\n",
    "if project_root_dir not in sys.path:\n",
    "    sys.path.append(project_root_dir)\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import config\n",
    "\n",
    "plt.style.use('seaborn')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Samson"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataset import HSIDataset\n",
    "from torch import tensor\n",
    "import scipy.io as sio\n",
    "\n",
    "class Samson(HSIDataset):\n",
    "    def __init__(self, root_dir, transform=None):\n",
    "        super(Samson, self).__init__()\n",
    "\n",
    "        data = sio.loadmat(os.path.join(root_dir, 'Data_Matlab/samson_1.mat'))\n",
    "        y = sio.loadmat(os.path.join(root_dir, 'GroundTruth/end3.mat'))\n",
    "\n",
    "\n",
    "        self.n_row, self.n_col , self.n_bands = data['nRow'].item(), data['nCol'].item(), data['nBand'].item()\n",
    "\n",
    "        self.X = data['V'].T.reshape(self.n_row, self.n_col, -1) # (nRow, nCol, nBand)\n",
    "        self.X = self.preprocessing(self.X).reshape(-1, self.X.shape[-1]) # (nRow*nCol, nBand)\n",
    "        self.X = tensor(self.X, dtype=torch.float32)\n",
    "\n",
    "        self.E = tensor(y['M'].T, dtype=torch.float32) # (nEndmember, nBand)\n",
    "        self.A = tensor(y['A'].T, dtype=torch.float32) # (nRow*nCol, nEndmember)\n",
    "        self.n_endmembers = self.E.shape[0]\n",
    "        \n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.n_row * self.n_col\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        sample = self.X[idx]\n",
    "        if self.transform:\n",
    "            sample = self.transform(sample)\n",
    "\n",
    "        return sample\n",
    "\n",
    "    def endmembers(self):\n",
    "        return self.E\n",
    "\n",
    "    def abundance(self):\n",
    "        return self.A.reshape(self.n_row, self.n_col, -1)\n",
    "\n",
    "    def image(self):\n",
    "        return self.X.reshape(self.n_row, self.n_col, -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = Samson(config.Samson_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from HySpecLab.metrics import UnmixingLoss, NormalizedEntropy\n",
    "from HySpecLab.metrics.regularization import SimplexVolumeLoss, SimilarityLoss\n",
    "\n",
    "from HySpecLab.unmixing import ContrastiveUnmixing\n",
    "from tqdm import tqdm\n",
    "from torch.optim.lr_scheduler import StepLR\n",
    "from torch import sigmoid\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "def train(model:nn.Module, n_endmembers:int, dataset:Dataset, n_batchs:int = 64, n_epochs:int = 100, lr=1e-3):\n",
    "    device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "    model = model.to(device)\n",
    "    model.train()\n",
    "\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "    # optimizer = torch.optim.SGD(model.parameters(), lr=lr)\n",
    "    criterion = UnmixingLoss()\n",
    "    entropy_reg  = NormalizedEntropy(S=n_endmembers)    \n",
    "    volume_reg = SimplexVolumeLoss(dataset[:], n_endmembers).to(device)\n",
    "    similarity_reg = SimilarityLoss(n_endmembers, temperature=.1, reduction='mean')\n",
    "\n",
    "\n",
    "    dataloader = DataLoader(dataset, batch_size=int(len(dataset)/n_batchs), shuffle=True)\n",
    "\n",
    "    epoch_iterator = tqdm(\n",
    "            range(n_epochs),\n",
    "            leave=True,\n",
    "            unit=\"epoch\",\n",
    "            postfix={\"tls\": \"%.4f\" % -1},\n",
    "        )\n",
    "\n",
    "    entropy_weight = 1e-1\n",
    "    simplex_weight = 1e-4\n",
    "    similarity_weight = 1e-1\n",
    "\n",
    "    # entropy_weight = 0\n",
    "    # simplex_weight = 0\n",
    "    # similarity_weight = 0\n",
    "\n",
    "    scaler = torch.cuda.amp.GradScaler()\n",
    "\n",
    "    for epoch in epoch_iterator:\n",
    "        epoch_loss = 0.\n",
    "        for i, (x) in enumerate(dataloader):\n",
    "            x = x.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            y = model(x)\n",
    "            loss = criterion(y, x) + entropy_weight*entropy_reg(model.A) + simplex_weight*volume_reg(sigmoid(model.ebk)) + similarity_weight*similarity_reg(model.ebk)\n",
    "            epoch_loss += loss.detach().item()\n",
    "\n",
    "            scaler.scale(loss).backward()\n",
    "            scaler.step(optimizer)\n",
    "            scaler.update()\n",
    "            \n",
    "        epoch_iterator.set_postfix(tls=\"%.4f\" % (epoch_loss/(i+1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from HySpecLab.eea import VCA\n",
    "n_endmembers = dataset.n_endmembers + 0\n",
    "\n",
    "vca = VCA(n_endmembers=n_endmembers, snr_input=0, random_state=42)\n",
    "\n",
    "E = vca.fit(dataset.X.numpy())\n",
    "endmember_init = torch.from_numpy(vca.endmembers()).float()\n",
    "# forces that the max value of each ealemend is 1 - 1e-3, For testing!!\n",
    "endmember_init = (endmember_init / endmember_init.max(dim=1, keepdim=True)[0]) * .9\n",
    "logit_endmember_init = torch.log((endmember_init / (1-endmember_init) + 1e-12))\n",
    "\n",
    "\n",
    "with plt.style.context((\"seaborn-colorblind\")):\n",
    "    plt.plot(endmember_init.T)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from pysptools import eea\n",
    "# n_endmembers = dataset.n_endmembers + 25\n",
    "\n",
    "# ee = eea.NFINDR()\n",
    "# endmember = ee.extract(dataset.image().numpy(), n_endmembers)\n",
    "# endmember_init = torch.from_numpy(endmember).float()\n",
    "# logit_endmember_init = torch.log((endmember_init / (1-endmember_init) + 1e-12))\n",
    "\n",
    "# with plt.style.context((\"seaborn-colorblind\")):\n",
    "#     plt.plot(endmember_init.T)\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# n_endmembers = dataset.n_endmembers + 0\n",
    "\n",
    "# ee = eea.FIPPI()\n",
    "# endmember = ee.extract(dataset.image().numpy(), n_endmembers-1)\n",
    "# endmember_init = torch.from_numpy(endmember).float()\n",
    "# endmember_init = endmember_init[1:]\n",
    "# logit_endmember_init = torch.log((endmember_init / (1-endmember_init) + 1e-12))\n",
    "\n",
    "# with plt.style.context((\"seaborn-colorblind\")):\n",
    "#     plt.plot(endmember_init.T)\n",
    "# plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_bands = dataset.n_bands\n",
    "model = ContrastiveUnmixing(n_bands, n_endmembers, endmember_init=logit_endmember_init)\n",
    "# train(model, n_endmembers, dataset, n_batchs=32, n_epochs=100, lr=1e-3)\n",
    "train(model, n_endmembers, dataset, n_batchs=80, n_epochs=120, lr=1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = UnmixingLoss()\n",
    "entropy_reg  = NormalizedEntropy(S=n_endmembers)\n",
    "volume_reg = SimplexVolumeLoss(dataset[:], n_endmembers)\n",
    "similarity_reg = SimilarityLoss(n_endmembers, temperature=.1, reduction='mean')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_X = dataset.X\n",
    "\n",
    "model.eval()\n",
    "model = model.cpu()\n",
    "reconstruc = model(_X)\n",
    "with torch.no_grad():\n",
    "    print(criterion(reconstruc, _X).cpu(), entropy_reg(model.A).cpu(), volume_reg(sigmoid(model.ebk)).cpu(),\n",
    "         similarity_reg(sigmoid(model.ebk)).cpu())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = list(map(lambda x: f'$E_{x}$', range(1, n_endmembers+1)))\n",
    "ebk = sigmoid(model.ebk).detach().cpu()\n",
    "with plt.style.context((\"seaborn-colorblind\")):\n",
    "    fig = plt.figure(figsize=(7, 5))\n",
    "    plt.plot(ebk.T, label=labels)\n",
    "    plt.ylabel('Reflectance', fontsize='x-large')\n",
    "    plt.xlabel('Bands', fontsize='x-large')\n",
    "    #legend background white\n",
    "    plt.legend(fontsize='x-large', facecolor='white')\n",
    "    plt.xticks(fontsize='x-large')\n",
    "    plt.yticks(fontsize='x-large')\n",
    "    plt.tight_layout()\n",
    "    \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ordering the endmembers\n",
    "endmembers = dataset.endmembers().detach().cpu()\n",
    "from HySpecLab.metrics import sad\n",
    "sad_result = sad(ebk, endmembers)\n",
    "print(sad_result)\n",
    "idx = torch.argmin(sad_result, dim=1) # Index for reordering the ground truth\n",
    "print(idx)\n",
    "\n",
    "# reorder the endmembers\n",
    "endmembers = endmembers[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = list(map(lambda x: f'$E_{x}$', range(1, len(dataset.endmembers())+1)))\n",
    "with plt.style.context((\"seaborn-colorblind\")):\n",
    "    fig = plt.figure(figsize=(7, 5))\n",
    "    plt.plot(endmembers.T, label=labels)\n",
    "    plt.ylabel('Reflectance', fontsize='x-large')\n",
    "    plt.xlabel('Bands', fontsize='x-large')\n",
    "    plt.legend(fontsize='x-large', facecolor='white')\n",
    "    plt.xticks(fontsize='x-large')\n",
    "    plt.yticks(fontsize='x-large')\n",
    "    # plt.title('Ground Truth', fontsize='x-large')\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.nn.functional import softmax\n",
    "test = softmax(model.A.detach(), dim=1).cpu().numpy().reshape(dataset.n_row, dataset.n_col, n_endmembers)\n",
    "labels = list(map(lambda x: f'$E_{x}$', range(1, n_endmembers+1)))\n",
    "\n",
    "# with plt.style.context((\"seaborn-colorblind\")):\n",
    "fig = plt.figure(figsize=(12,7))\n",
    "for i in range(n_endmembers):\n",
    "    plt.subplot(4,5,i+1)\n",
    "    # plt.imshow(test[:,:,i].T, vmin=0, vmax=softmax(model.A, dim=1).max(), cmap='viridis')\n",
    "    plt.imshow(test[:,:,i].T, cmap='viridis')\n",
    "    plt.xticks([])\n",
    "    plt.yticks([])\n",
    "    plt.title(labels[i], fontsize='x-large')\n",
    "    plt.colorbar()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ebk = sigmoid(model.ebk).detach().cpu()\n",
    "endmembers = dataset.endmembers()\n",
    "\n",
    "from torch.nn.functional import mse_loss\n",
    "def rmse(x: torch.Tensor, y: torch.Tensor):\n",
    "    return torch.sqrt(mse_loss(x, y, reduction='none').mean(dim=1))\n",
    "\n",
    "abundance = softmax(model.A.detach(), dim=1).cpu().reshape(dataset.n_row, dataset.n_col, n_endmembers)\n",
    "abundance = abundance.permute(2,0,1)\n",
    "abundance_gt = dataset.abundance()[:,:,idx].permute(2,0,1) # Reorder the ground truth\n",
    "endmember_gt = dataset.endmembers()[idx, :]\n",
    "\n",
    "rmse_result = rmse(abundance.flatten(1), abundance_gt.flatten(1))\n",
    "print(rmse_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(12,7))\n",
    "for i in range(n_endmembers):\n",
    "    plt.subplot(4,5,i+1)\n",
    "    # plt.imshow(test[:,:,i].T, vmin=0, vmax=softmax(model.A, dim=1).max(), cmap='viridis')\n",
    "    plt.imshow(abundance_gt[i,:,:].T, cmap='viridis')\n",
    "    plt.xticks([])\n",
    "    plt.yticks([])\n",
    "    plt.title(labels[i], fontsize='x-large')\n",
    "    plt.colorbar()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Urban dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataset import HSIDataset\n",
    "from torch import tensor\n",
    "import scipy.io as sio\n",
    "\n",
    "class Urban(HSIDataset):\n",
    "    def __init__(self, root_dir, transform=None):\n",
    "        super(Urban, self).__init__()\n",
    "\n",
    "        data = sio.loadmat(os.path.join(root_dir, 'Urban_R162.mat'))\n",
    "        y = sio.loadmat(os.path.join(root_dir, 'groundTruth/end4_groundTruth.mat'))\n",
    "\n",
    "\n",
    "        self.n_row, self.n_col , self.n_bands = data['nRow'].item(), data['nCol'].item(), data['nBand'].item()\n",
    "\n",
    "        self.X = data['Y'].T.reshape(self.n_row, self.n_col, -1) # (nRow, nCol, nBand)\n",
    "        self.X = self.preprocessing(self.X).reshape(-1, self.X.shape[-1]) # (nRow*nCol, nBand)\n",
    "        self.X = tensor(self.X, dtype=torch.float32)\n",
    "\n",
    "        self.E = tensor(y['M'].T, dtype=torch.float32) # (nEndmember, nBand)\n",
    "        self.A = tensor(y['A'].T, dtype=torch.float32) # (nRow*nCol, nEndmember)\n",
    "        self.n_endmembers = self.E.shape[0]\n",
    "        \n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.n_row * self.n_col\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        sample = self.X[idx]\n",
    "        if self.transform:\n",
    "            sample = self.transform(sample)\n",
    "\n",
    "        return sample\n",
    "\n",
    "    def endmembers(self):\n",
    "        return self.E\n",
    "\n",
    "    def abundance(self):\n",
    "        return self.A.reshape(self.n_row, self.n_col, -1)\n",
    "\n",
    "    def image(self):\n",
    "        return self.X.reshape(self.n_row, self.n_col, -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = Urban(root_dir=config.Urban_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(dataset.abundance()[:,:,3], cmap='viridis')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ResearchStay",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "41f72df89919d74d3a449896230e7539fdf54ec0bbe47e8a03d934e2ec4dfa40"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
